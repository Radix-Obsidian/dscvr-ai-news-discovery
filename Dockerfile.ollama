FROM ollama/ollama:latest

# Set working directory
WORKDIR /root

# Expose Ollama port
EXPOSE 11434

# Set environment variables for Railway
ENV OLLAMA_HOST=0.0.0.0:11434
ENV OLLAMA_ORIGINS=*

# Create a script to download models and start Ollama
RUN echo '#!/bin/bash\n\
# Start Ollama in the background\n\
ollama serve &\n\
\n\
# Wait for Ollama to be ready\n\
echo "Waiting for Ollama to start..."\n\
sleep 10\n\
\n\
# Download the default model if specified\n\
if [ ! -z "$OLLAMA_MODEL" ]; then\n\
    echo "Downloading model: $OLLAMA_MODEL"\n\
    ollama pull $OLLAMA_MODEL\n\
fi\n\
\n\
# Keep the container running\n\
wait\n\
' > /root/start-ollama.sh

# Make the script executable
RUN chmod +x /root/start-ollama.sh

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=120s --retries=5 \
    CMD curl -f http://localhost:11434/api/tags || exit 1

# Start the script
CMD ["/root/start-ollama.sh"]
